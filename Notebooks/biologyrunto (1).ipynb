{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10333434,"sourceType":"datasetVersion","datasetId":6309771}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments\nfrom huggingface_hub import HfApi, login\nfrom torch.utils.data import Dataset\nfrom datasets import load_dataset\nimport torch\nimport json\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T12:24:35.422357Z","iopub.execute_input":"2024-12-30T12:24:35.423019Z","iopub.status.idle":"2024-12-30T12:24:53.463061Z","shell.execute_reply.started":"2024-12-30T12:24:35.422967Z","shell.execute_reply":"2024-12-30T12:24:53.462172Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load the pre-trained BART model and tokenizer\nmodel_name = 'facebook/bart-large'\nmodel = BartForConditionalGeneration.from_pretrained(model_name)\ntokenizer = BartTokenizer.from_pretrained(model_name)\n\n# Define a function to generate responses\ndef respond(input_text=\"\"):\n    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n    response_ids = model.generate(input_ids, max_length=125, num_beams=5, early_stopping=True)\n    response = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n    return response\n\n# Test the function\noutput = respond(input_text=\"What is biology\")\nprint(output)\n\n\nwith open(\"/kaggle/input/biologyrunto-dataset/chatbot_dataset.json\", \"r\") as file:\n    dataset=json.load(file)\n\ndef tokenize_function(examples):\n    inputs = tokenizer(examples['input'], padding='max_length', truncation=True, max_length=128)\n    outputs = tokenizer(examples['output'], padding='max_length', truncation=True, max_length=128)\n    inputs['labels'] = outputs['input_ids']\n    return inputs\n\ntokenized_dataset = [tokenize_function(example) for example in dataset]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T12:24:53.464668Z","iopub.execute_input":"2024-12-30T12:24:53.465403Z","iopub.status.idle":"2024-12-30T12:25:07.763918Z","shell.execute_reply.started":"2024-12-30T12:24:53.465363Z","shell.execute_reply":"2024-12-30T12:25:07.762965Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec99d1e3217d44c081ab23fd7fc91ae8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4ac67602ec640aa8cec4103e31127d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a9394b28f754427970a26e441ebc8c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eacae0e44cbf412095d601ed50644000"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97dcd1137fd54730b6ec4e5838c5e7b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1bb46328b54c2fb3f3926811daac1f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"What is it?\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Convert to a format compatible with the Trainer\nclass CustomDataset(Dataset):\n    def __init__(self, tokenized_dataset):\n        self.dataset = tokenized_dataset\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val) for key, val in self.dataset[idx].items()}\n\ntrain_dataset = CustomDataset(tokenized_dataset)\n\n# Define training arguments with a different run name\ntraining_args = TrainingArguments(\n    output_dir='./BiologyRunto-model',\n    #run_name='BiologyRunto_Training_Run',  # Set a different run name\n    num_train_epochs=3,\n    per_device_train_batch_size=2,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n \n# Create Trainer instance\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,  # Your dataset here\n)\n\n# Start training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T12:25:07.765077Z","iopub.execute_input":"2024-12-30T12:25:07.765336Z","iopub.status.idle":"2024-12-30T12:35:07.324345Z","shell.execute_reply.started":"2024-12-30T12:25:07.765312Z","shell.execute_reply":"2024-12-30T12:35:07.323196Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113661055555389, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"274dbe2737ac4ad787eeeb8a57085c6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241230_122522-gnuits0e</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/adesegundaniel01/huggingface/runs/gnuits0e' target=\"_blank\">./BiologyRunto-model</a></strong> to <a href='https://wandb.ai/adesegundaniel01/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/adesegundaniel01/huggingface' target=\"_blank\">https://wandb.ai/adesegundaniel01/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/adesegundaniel01/huggingface/runs/gnuits0e' target=\"_blank\">https://wandb.ai/adesegundaniel01/huggingface/runs/gnuits0e</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2730' max='2730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2730/2730 09:40, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.846500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.953900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.726400</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.601100</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.486600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2730, training_loss=0.8857908227941492, metrics={'train_runtime': 596.844, 'train_samples_per_second': 9.143, 'train_steps_per_second': 4.574, 'total_flos': 1478236226715648.0, 'train_loss': 0.8857908227941492, 'epoch': 3.0})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Save the fine-tuned model and tokenizer\nmodel.save_pretrained('/kaggle/working/BiologyRunto-model')\ntokenizer.save_pretrained('/kaggle/working/BiologyRunto-model')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T12:42:35.983479Z","iopub.execute_input":"2024-12-30T12:42:35.984370Z","iopub.status.idle":"2024-12-30T12:42:40.668528Z","shell.execute_reply.started":"2024-12-30T12:42:35.984318Z","shell.execute_reply":"2024-12-30T12:42:40.667734Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/BiologyRunto-model/tokenizer_config.json',\n '/kaggle/working/BiologyRunto-model/special_tokens_map.json',\n '/kaggle/working/BiologyRunto-model/vocab.json',\n '/kaggle/working/BiologyRunto-model/merges.txt',\n '/kaggle/working/BiologyRunto-model/added_tokens.json')"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Load the model and tokenizer\nmodel_name = '/kaggle/working/BiologyRunto-model'\nmodel = BartForConditionalGeneration.from_pretrained(model_name)\ntokenizer = BartTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T12:43:34.226291Z","iopub.execute_input":"2024-12-30T12:43:34.226628Z","iopub.status.idle":"2024-12-30T12:43:35.382330Z","shell.execute_reply.started":"2024-12-30T12:43:34.226602Z","shell.execute_reply":"2024-12-30T12:43:35.381584Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def respond(input_text=\"\"):\n    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n    response_ids = model.generate(input_ids, max_length=130, num_beams=10, early_stopping=True)\n    response = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T12:52:23.050259Z","iopub.execute_input":"2024-12-30T12:52:23.051042Z","iopub.status.idle":"2024-12-30T12:52:23.056197Z","shell.execute_reply.started":"2024-12-30T12:52:23.051007Z","shell.execute_reply":"2024-12-30T12:52:23.055373Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"output=respond(input_text=\"what are the components of a plant cell\")\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T12:52:24.423063Z","iopub.execute_input":"2024-12-30T12:52:24.423967Z","iopub.status.idle":"2024-12-30T12:52:48.833126Z","shell.execute_reply.started":"2024-12-30T12:52:24.423907Z","shell.execute_reply":"2024-12-30T12:52:48.832085Z"}},"outputs":[{"name":"stdout","text":"The components of a plant cell include:\n1. Cytoplasm: The gel-like substance that fills the cell.\n2. Nucleus: The organelle that contains the cell's genetic material (DNA) and controls cellular activities.\n3. Endoplasmic reticulum: The membrane-bound organelles that store and transport nutrients, waste products, and waste products.\n4. Golgi apparatus: The apparatus that maintains cell shape and maintains turgor pressure.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"login(token=\"put your assess token here\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T12:53:35.433875Z","iopub.execute_input":"2024-12-30T12:53:35.434608Z","iopub.status.idle":"2024-12-30T12:53:35.674481Z","shell.execute_reply.started":"2024-12-30T12:53:35.434573Z","shell.execute_reply":"2024-12-30T12:53:35.673674Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"api = HfApi()\napi.upload_folder(\n    folder_path=\"/kaggle/working/BiologyRunto-model\",\n    repo_id=\"AdesegunDaniel/BiologyRunto\",\n    repo_type=\"model\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T12:53:42.011010Z","iopub.execute_input":"2024-12-30T12:53:42.011812Z","iopub.status.idle":"2024-12-30T12:55:40.420817Z","shell.execute_reply.started":"2024-12-30T12:53:42.011781Z","shell.execute_reply":"2024-12-30T12:55:40.420006Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"optimizer.pt:   0%|          | 0.00/3.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b65775b172c94ae9b4f859ccb96cf3a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rng_state.pth:   0%|          | 0.00/14.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"008731a566874d59b66d45b576f36da7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce7cdc39604e4634ad1cd066f26bc41a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"677eaa89c1b742b8915d15c2ab2eb295"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 7 LFS files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3154004237d8438b8e21281c4743e2ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler.pt:   0%|          | 0.00/1.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d2cb81d99454ec6be47a22f1babac00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8351ad42f930446b83c6add8f7913dfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735561510.c0d6bc280cc8.30.0:   0%|          | 0.00/7.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bbfb4d179c84a3b99670c23b8a6d4e4"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/AdesegunDaniel/BiologyRunto/commit/2fe1fcbd72d1f55334ac18eed9888878ec6f483a', commit_message='Upload folder using huggingface_hub', commit_description='', oid='2fe1fcbd72d1f55334ac18eed9888878ec6f483a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/AdesegunDaniel/BiologyRunto', endpoint='https://huggingface.co', repo_type='model', repo_id='AdesegunDaniel/BiologyRunto'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\nimport os\n\n\nmodel_name = \"AdesegunDaniel/BiologyRunto\"\nmodel = BartForConditionalGeneration.from_pretrained(model_name)\ntokenizer = BartTokenizer.from_pretrained(model_name)\n\ndef respond(input_text=\"\"):\n    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n    response_ids = model.generate(input_ids, max_length=100, num_beams=3, early_stopping=True)\n    response = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n    return response\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:23:32.397286Z","iopub.execute_input":"2024-12-30T18:23:32.397545Z","iopub.status.idle":"2024-12-30T18:24:19.335077Z","shell.execute_reply.started":"2024-12-30T18:23:32.397519Z","shell.execute_reply":"2024-12-30T18:24:19.334151Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14e30041fc714fb989056c3c32efda95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41f3354114b44a9b8700289406d44bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/292 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4440a39162204f319451432ceef65efa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f63588ed91a3459ba02b0b95c0f59965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/999k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9233347278674e939c1b28c634b907ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d70578f0198d4b0786f5432ee9bcf0ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9b4efdc82ab4599b22a0ae2013bdb75"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"user_input = 'what is skeleton'\nbot_response = respond(user_input)\nprint(bot_response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:24:27.547033Z","iopub.execute_input":"2024-12-30T18:24:27.547418Z","iopub.status.idle":"2024-12-30T18:24:32.199926Z","shell.execute_reply.started":"2024-12-30T18:24:27.547387Z","shell.execute_reply":"2024-12-30T18:24:32.198891Z"}},"outputs":[{"name":"stdout","text":"Skeleton is a structure made of bone and cartilage that provides support and protection to the body's organs and tissues. It is composed of microtubules arranged in a '9+2' pattern and provides structural support and rigidity. Skeletons are found in vertebrates, including humans, and play a crucial role in maintaining overall health and function.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}